# Airflow local pipeline (medallion) â€” instruÃ§Ãµes e novidades

Este repositÃ³rio contÃ©m uma instÃ¢ncia local do Apache Airflow em Docker com uma
pipeline Medallion (Bronze â†’ Silver â†’ Gold). Este README foi atualizado para
documentar as novas features implementadas: scripts separados para cada camada,
logging em JSON, verificaÃ§Ã£o de qualidade de dados (DQ) e um sistema de alertas
por eâ€‘mail (com MailHog para testes locais e opÃ§Ã£o de SMTP real).

## Architecture

### Blueprint e Components Principais

A arquitetura segue o padrÃ£o **Medallion Architecture** (camadas Bronze â†’ Silver â†’ Gold) com orquestraÃ§Ã£o por Apache Airflow:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Apache Airflow (Docker)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  medallion_pipeline (DAG)                                        â”‚   â”‚
â”‚  â”‚  â”œâ”€ bronze_task      â†’ IngestÃ£o / API externa (JSON)             â”‚   â”‚
â”‚  â”‚  â”œâ”€ silver_task      â†’ TransformaÃ§Ã£o (Parquet particionado)      â”‚   â”‚
â”‚  â”‚  â”œâ”€ dq_check_task    â†’ ValidaÃ§Ã£o de qualidade                    â”‚   â”‚
â”‚  â”‚  â””â”€ gold_task        â†’ AgregaÃ§Ã£o final (Delta Lake)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                         â”‚
â”‚  Services: Webserver + Scheduler                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Data Layers (Local Storage)                      â”‚
â”‚                                                                         â”‚
â”‚  ğŸ“ /opt/airflow/data/                                                  â”‚
â”‚  â”œâ”€ bronze/           â† JSON raw (Open Brewery DB)                      â”‚
â”‚  â”œâ”€ silver/           â† Parquet (cleaned, transformed)                  â”‚
â”‚  â”œâ”€ gold_delta/       â† Delta Lake (aggregated, indexed)                â”‚
â”‚  â””â”€ logging/          â† JSON logs (execution metrics + DQ alerts)       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Observability & Alerting                             â”‚
â”‚                                                                         â”‚
â”‚  ğŸ“§ Email Alerts (Airflow + SMTP)  â†’ MailHog (local) ou SMTP real      â”‚
â”‚  ğŸ“Š JSON Logging                   â†’ Audit trail de execuÃ§Ãµes          â”‚
â”‚  ğŸ¥ Health Checks                  â†’ Endpoint /health (webserver)      â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Bronze (IngestÃ£o)**
   - Fetch de dados da API (Open Brewery DB)
   - Armazenamento como JSON bruto em `/data/bronze/`
   - Naming: `bronze_breweries_<TIMESTAMP>.json`

2. **Silver (TransformaÃ§Ã£o)**
   - Leitura de arquivos Bronze JSON
   - Limpeza, validaÃ§Ã£o, casting de tipos
   - RemoÃ§Ã£o de duplicatas e valores nulos
   - Armazenamento particionado em Parquet em `/data/silver/run_<TIMESTAMP>/`

3. **DQ Check (ValidaÃ§Ã£o)**
   - AvaliaÃ§Ã£o de regras (contagem de registros, valores nulos, ranges)
   - GeraÃ§Ã£o de logs JSON com mÃ©tricas
   - Trigger de alertas via eâ€‘mail se violaÃ§Ãµes encontradas

4. **Gold (AgregaÃ§Ã£o)**
   - Leitura de dados Silver
   - AgregaÃ§Ãµes: contagem por estado, tipo de cervejaria, etc.
   - Tentativa de escrita em Delta Lake (`/data/gold_delta/`)
   - Fallback para Parquet se Delta indisponÃ­vel

### Technology Stack

| Componente | Tecnologia |
|-----------|-----------|
| **OrquestraÃ§Ã£o** | Apache Airflow 2.8.0 |
| **Python** | 3.11 |
| **Storage** | Local (Parquet, JSON, Delta Lake) |
| **Pipeline Type** | Batch (scheduled) |
| **Logging** | JSON custom + Airflow logs |
| **Alertas** | SMTP (MailHog/Real) + Airflow email op |
| **ContainerizaÃ§Ã£o** | Docker + Docker Compose |

### Estrutura de Pastas

```
airflow_home/
â”œâ”€ dags/
â”‚  â”œâ”€ medallion_pipeline_dag.py     (DAG principal)
â”‚  â””â”€ scripts/                      (lÃ³gica separada por camada)
â”‚     â”œâ”€ bronze.py
â”‚     â”œâ”€ silver.py
â”‚     â”œâ”€ gold.py
â”‚     â”œâ”€ dq.py
â”‚     â”œâ”€ logging.py
â”‚     â””â”€ alert.py
â”œâ”€ data/
â”‚  â”œâ”€ bronze/                       (JSON bruto)
â”‚  â”œâ”€ silver/                       (Parquet transformado)
â”‚  â”œâ”€ gold_delta/                   (Delta Lake)
â”‚  â””â”€ logging/                      (JSON logs)
â””â”€ logs/                            (Airflow task logs)

config/                             (ConfiguraÃ§Ãµes customizadas)
plugins/                            (Plugins Airflow customizados)
```

Resumo rÃ¡pido
- OrquestraÃ§Ã£o: Airflow (webserver + scheduler) via `docker-compose`.
- Pipeline: `medallion_pipeline` (tasks: bronze_task, silver_task, dq_check_task, gold_task).
- Scripts: implementaÃ§Ãµes extraÃ­das para `airflow_home/dags/scripts/` â€” `bronze.py`,
  `silver.py`, `gold.py`, `logging.py`, `dq.py`, `alert.py`.
- Logging: eventos de execuÃ§Ã£o e mÃ©tricas DQ escritos como JSON em
  `/opt/airflow/data/logging` (um arquivo JSON por evento).
- Alertas: envio de eâ€‘mail em caso de falhas/DQ via Airflow `send_email` com
  fallback por `smtplib`. Para testes locais, MailHog estÃ¡ integrado ao
  `docker-compose`.

Arquivos principais criados/alterados
- `airflow_home/dags/medallion_pipeline_dag.py` â€” DAG que delega lÃ³gica aos scripts.
- `airflow_home/dags/scripts/bronze.py` â€” fetch e gravaÃ§Ã£o Bronze (JSON).
- `airflow_home/dags/scripts/silver.py` â€” transformaÃ§Ã£o Silver (Parquet particionado).
- `airflow_home/dags/scripts/gold.py` â€” agregaÃ§Ã£o Gold e tentativa de escrita Delta.
- `airflow_home/dags/scripts/logging.py` â€” helper para gravar eventos JSON em
  `/opt/airflow/data/logging`.
- `airflow_home/dags/scripts/dq.py` â€” avaliador de regras de qualidade e gerador
  de alertas.
- `airflow_home/dags/scripts/alert.py` â€” helper de envio de eâ€‘mail (Airflow + SMTP
  fallback).
- `docker-compose.yml` â€” adicionado serviÃ§o `mailhog` e variÃ¡veis SMTP de exemplo.

Como rodar (modo rÃ¡pido)
1. Subir os containers:

```powershell
docker-compose up -d
```

2. Acesse a UI do Airflow: http://localhost:8080
3. Para ver as mensagens capturadas pelo MailHog (teste local):
   - UI MailHog: http://localhost:8025
   - API MailHog: http://localhost:8025/api/v2/messages

Testes manuais Ãºteis (PowerShell)
- Listar DAGs:

```powershell
docker-compose run --rm airflow-webserver airflow dags list
```

- Executar tasks isoladas (Ãºtil para debug):

```powershell
# executar bronze (gera /opt/airflow/data/bronze/*.json)
docker-compose run --rm airflow-webserver airflow tasks test medallion_pipeline bronze_task 2026-01-18

# executar silver (gera /opt/airflow/data/silver/run_<timestamp>)
docker-compose run --rm airflow-webserver airflow tasks test medallion_pipeline silver_task 2026-01-18

# executar dq_check (avaliador de qualidade e envio de alerta se necessÃ¡rio)
docker-compose run --rm airflow-webserver airflow tasks test medallion_pipeline dq_check_task 2026-01-18

# executar gold
docker-compose run --rm airflow-webserver airflow tasks test medallion_pipeline gold_task 2026-01-18
```

ObservaÃ§Ã£o: ao usar `airflow tasks test` na task `dq_check_task` sem fornecer
`silver_path`, o checker pode nÃ£o localizar o log correto â€” o fluxo endâ€‘toâ€‘end
(bronze â†’ silver â†’ dq_check) em uma mesma execuÃ§Ã£o Ã© a forma mais realista de
testar.

ConfiguraÃ§Ã£o de SMTP (para enviar eâ€‘mails a caixas reais)

Por padrÃ£o este repositÃ³rio estÃ¡ configurado para usar MailHog (local) para
testes. Para enviar eâ€‘mails para contas reais (Hotmail, Gmail, etc.) vocÃª deve
fornecer credenciais SMTP de um provedor confiÃ¡vel (SendGrid, Mailgun, SES,
ou SMTP do seu domÃ­nio). Existem duas opÃ§Ãµes:

1) Usar um serviÃ§o de envio (recomendado)
   - Crie/obtenha credenciais no provedor (ex.: SendGrid API key ou Mailgun SMTP).
   - Atualize `docker-compose.yml` nas seÃ§Ãµes `airflow-webserver` e
     `airflow-scheduler` com as variÃ¡veis abaixo (exemplo SendGrid):

```yaml
environment:
  - AIRFLOW__SMTP__SMTP_HOST=smtp.sendgrid.net
  - AIRFLOW__SMTP__SMTP_PORT=587
  - AIRFLOW__SMTP__SMTP_MAIL_FROM=no-reply@seudominio.com
  - AIRFLOW__SMTP__SMTP_USER=apikey
  - AIRFLOW__SMTP__SMTP_PASSWORD=<SUA_SENDGRID_API_KEY>
  - AIRFLOW__SMTP__SMTP_STARTTLS=True
  - AIRFLOW__SMTP__SMTP_SSL=False

  # fallback usado por scripts/alert.py (opcional)
  - ALERT_SMTP_HOST=smtp.sendgrid.net
  - ALERT_SMTP_PORT=587
  - ALERT_SMTP_USER=apikey
  - ALERT_SMTP_PASSWORD=<SUA_SENDGRID_API_KEY>
  - ALERT_SMTP_FROM=no-reply@seudominio.com
  - ALERT_SMTP_USE_TLS=True
```

2) Usar um serviÃ§o de inbox de testes (Mailtrap, Ethereal)
   - Crie conta no serviÃ§o, obtenha credenciais SMTP e use no compose como
     acima. Esses serviÃ§os nÃ£o entregam Ã  internet, mas permitem ver a mensagem
     em uma inbox web (Ãºtil para validaÃ§Ã£o sem afetar destinatÃ¡rios reais).

Rebuild / dependÃªncias
- Se vocÃª pretende usar Delta Lake (`deltalake`) ou manipular Parquet com
  `pandas`/`pyarrow` dentro do container, certifique-se de que `requirements.txt`
  contÃ©m as dependÃªncias necessÃ¡rias e reconstrua a imagem:

```powershell
docker-compose build --no-cache
docker-compose up -d
```

